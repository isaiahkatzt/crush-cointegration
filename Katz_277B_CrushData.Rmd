---
title: "PSTAT 277B: Soybean Crush Data"
author: "Isaiah Katz"
date: "Winter 2024"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, warning=F, message=F}
library(tidyverse)
library(urca)
library(tsDyn)
library(vars)
library(tseries)

library(MASS)
library(purrr)
library(readr)
library(anytime)
library(viridis)
library(grid)
library(gridExtra)
```

### PART 1: DATA CLEANING 
```{r, DATA READING AND CLEANING, fig.align = "center", out.width = "60%"}
# raw data read -- daily increments
zm <- read.csv("ProjectData/front-month/ZM-12YR-DAILY.csv")
zl <- read.csv("ProjectData/front-month/ZL-12YR-DAILY.csv")
zs <- read.csv("ProjectData/front-month/ZS-12YR-DAILY.csv")

zm.dt <- zm %>% mutate("datetime" = anytime(time)) %>% dplyr::select(close, datetime)
zl.dt <- zl %>% mutate("datetime" = anytime(time)) %>% dplyr::select(close, datetime)
zs.dt <- zs %>% mutate("datetime" = anytime(time)) %>% dplyr::select(close, datetime)

# data cleaning check 
sum(zl.dt$datetime != zs.dt$datetime)
sum(zm.dt$datetime != zl.dt$datetime)

crush.dat <- data.frame(cbind(zs.dt$datetime, zs.dt$close, zl.dt$close, zm.dt$close))
colnames(crush.dat) <- c("dt", "ZS", "ZL", "ZM")

crush.normalized <- crush.dat %>% 
  mutate(ZS = ZS/100, ZM = ZM * 0.022, ZL = ZL*(11/100))

ts.plot(cbind(zs.dt$close/100, zm.dt$close*0.022, zl.dt$close*(11/100)), 
        main = "Soybean, soymeal, and soyoil futures prices (scaled by crush ratios)", 
        lty = c(1:3), col = rainbow(3))
legend("bottomright", legend = c("Soybean $/bushel", "Soymeal $/bushel", "Soyoil $/bushel"),
       col = rainbow(3), lty = 1:3, cex = 0.8, bg = "white")

ts.plot(crush.normalized$ZS, 
        main = "Soybean front month future prices, $/bushel", ylab = "Price")
ts.plot(crush.normalized$ZL, 
        main = "Soyoil front month future prices, $/bushel",  ylab = "Price")
ts.plot(crush.normalized$ZM, 
        main = "Soymeal front month future prices, $/bushel", ylab = "Price")

normalized.crush.value <- crush.normalized$ZS - 
  1.1*crush.normalized$ZM - 0.9*crush.normalized$ZL
ts.plot(normalized.crush.value, main = "Soybean Crush ($/bushel)", 
        ylab = "Price", xlab = "Time")
```

```{r, FORWARD CURVE RECONSTRUCTION}
## raw data read -- futures months F,H,K,N,Q,U,X   
file.list <- list.files(path = "ProjectData/curve-reconstruct", 
                        pattern = ".csv", full.names = TRUE)
curve.data <- setNames(map(file.list, read_csv, show_col_types = FALSE), 
                       basename(file.list))

## data cleaning  
merge.lists <- list()
contract.months <- c("f", "h", "k", "n", "q", "u", "x")

for (prefix in contract.months) {
  merge.lists[[paste0("merge.list.", prefix)]] <- list()
}

for (i in 13:24) {
  f.merge <- list(curve.data[[paste0("ZSF", i, ".csv")]], 
                  curve.data[[paste0("ZSN", i, ".csv")]], 
                  curve.data[[paste0("ZSF", i + 1, ".csv")]])
  merge.lists$merge.list.f[[paste0("f", i, ".merge")]] <- f.merge
  
  h.merge <- list(curve.data[[paste0("ZSH", i, ".csv")]], 
                  curve.data[[paste0("ZSU", i, ".csv")]], 
                  curve.data[[paste0("ZSH", i + 1, ".csv")]])
  merge.lists$merge.list.h[[paste0("h", i, ".merge")]] <- h.merge
}

for (i in 12:23) {
  k.merge <- list(curve.data[[paste0("ZSK", i, ".csv")]], 
                  curve.data[[paste0("ZSX", i, ".csv")]], 
                  curve.data[[paste0("ZSK", i + 1, ".csv")]])
  merge.lists$merge.list.k[[paste0("k", i, ".merge")]] <- k.merge
  
  n.merge <- list(curve.data[[paste0("ZSN", i, ".csv")]], 
                  curve.data[[paste0("ZSF", i + 1, ".csv")]], 
                  curve.data[[paste0("ZSN", i + 1, ".csv")]])
  merge.lists$merge.list.n[[paste0("n", i, ".merge")]] <- n.merge
  
  q.merge <- list(curve.data[[paste0("ZSQ", i, ".csv")]], 
                  curve.data[[paste0("ZSH", i + 1, ".csv")]], 
                  curve.data[[paste0("ZSQ", i + 1, ".csv")]])
  merge.lists$merge.list.q[[paste0("q", i, ".merge")]] <- q.merge
  
  u.merge <- list(curve.data[[paste0("ZSU", i, ".csv")]], 
                  curve.data[[paste0("ZSH", i + 1, ".csv")]], 
                  curve.data[[paste0("ZSU", i + 1, ".csv")]])
  merge.lists$merge.list.u[[paste0("u", i, ".merge")]] <- u.merge
  
  x.merge <- list(curve.data[[paste0("ZSX", i, ".csv")]], 
                  curve.data[[paste0("ZSK", i + 1, ".csv")]], 
                  curve.data[[paste0("ZSX", i + 1, ".csv")]])
  merge.lists$merge.list.x[[paste0("x", i, ".merge")]] <- x.merge
}

curve.lists <- list()
for (prefix in contract.months) {
  curve.lists[[paste0("curve.list.", prefix)]] <- list()
}

merge.drop <- function(merge.list) {
  lapply(merge.list, function(data) 
    drop_na(Reduce(function(x, y) merge(x, y, by = "time"), data)))
}

for (contract in contract.months) {
  curve.lists[[paste0("curve.list.", contract)]] <-
    merge.drop(merge.lists[[paste0("merge.list.", contract)]])
}

cal.split <- function(data) {
  data %>% 
    mutate(six.mo = close.x - close.y, year = close.x - close) %>%
    dplyr::select(time, six.mo, year)
}

## contracts K12 - H13 
k12.data <- cal.split(curve.lists$curve.list.k$k12.merge) %>%
  filter(anydate(time) < as.Date("2012-04-01"))
n12.data <- cal.split(curve.lists$curve.list.n$n12.merge) %>%
  filter(anydate(time) >= as.Date("2012-04-01") & anydate(time) < as.Date("2012-06-01"))
u12.data <- cal.split(curve.lists$curve.list.u$u12.merge) %>% 
  filter(anydate(time) >= as.Date("2012-06-01") & anydate(time) < as.Date("2012-08-01"))
x12.data <- cal.split(curve.lists$curve.list.x$x12.merge) %>%
  filter(anydate(time) >= as.Date("2012-08-01") & anydate(time) < as.Date("2012-10-01"))
f13.data <- cal.split(curve.lists$curve.list.f$f13.merge) %>% 
  filter(anydate(time) >= as.Date("2012-10-01") & anydate(time) < as.Date("2012-12-01"))
h13.data <- cal.split(curve.lists$curve.list.h$h13.merge) %>%
  filter(anydate(time) >= as.Date("2012-12-01") & anydate(time) < as.Date("2013-02-01"))
cal12.13 <- rbind(k12.data, n12.data, u12.data, x12.data, f13.data, h13.data)

## contracts K13 - H14
k13.data <- cal.split(curve.lists$curve.list.k$k13.merge) %>% 
  filter(anydate(time) >= as.Date("2013-02-01") & anydate(time) < as.Date("2013-04-01"))
n13.data <- cal.split(curve.lists$curve.list.n$n13.merge) %>%
  filter(anydate(time) >= as.Date("2013-04-01") & anydate(time) < as.Date("2013-06-01"))
u13.data <- cal.split(curve.lists$curve.list.u$u13.merge) %>%
  filter(anydate(time) >= as.Date("2013-06-01") & anydate(time) < as.Date("2013-08-01"))
x13.data <- cal.split(curve.lists$curve.list.x$x13.merge) %>%
  filter(anydate(time) >= as.Date("2013-08-01") & anydate(time) < as.Date("2013-10-01"))
f14.data <- cal.split(curve.lists$curve.list.f$f14.merge) %>%
  filter(anydate(time) >= as.Date("2013-10-01") & anydate(time) < as.Date("2013-12-01"))
h14.data <- cal.split(curve.lists$curve.list.h$h14.merge) %>%
  filter(anydate(time) >= as.Date("2013-12-01") & anydate(time) < as.Date("2014-02-01"))
cal13.14 <- rbind(k13.data, n13.data, u13.data, x13.data, f14.data, h14.data)

## contracts K14 - H15
k14.data <- cal.split(curve.lists$curve.list.k$k14.merge) %>%
  filter(anydate(time) >= as.Date("2014-02-01") & anydate(time) < as.Date("2014-04-01"))
n14.data <- cal.split(curve.lists$curve.list.n$n14.merge) %>%
  filter(anydate(time) >= as.Date("2014-04-01") & anydate(time) < as.Date("2014-06-01"))
u14.data <- cal.split(curve.lists$curve.list.u$u14.merge) %>%
  filter(anydate(time) >= as.Date("2014-06-01") & anydate(time) < as.Date("2014-08-01"))
x14.data <- cal.split(curve.lists$curve.list.x$x14.merge) %>%
  filter(anydate(time) >= as.Date("2014-08-01") & anydate(time) < as.Date("2014-10-01"))
f15.data <- cal.split(curve.lists$curve.list.f$f15.merge) %>%
  filter(anydate(time) >= as.Date("2014-10-01") & anydate(time) < as.Date("2014-12-01"))
h15.data <- cal.split(curve.lists$curve.list.h$h15.merge) %>%
  filter(anydate(time) >= as.Date("2014-12-01") & anydate(time) < as.Date("2015-02-01"))
cal14.15 <- rbind(k14.data, n14.data, u14.data, x14.data, f15.data, h15.data)

## contracts K15 - H16
k15.data <- cal.split(curve.lists$curve.list.k$k15.merge) %>% 
  filter(anydate(time) >= as.Date("2015-02-01") & anydate(time) < as.Date("2015-04-01"))
n15.data <- cal.split(curve.lists$curve.list.n$n15.merge) %>%
  filter(anydate(time) >= as.Date("2015-04-01") & anydate(time) < as.Date("2015-06-01"))
u15.data <- cal.split(curve.lists$curve.list.u$u15.merge) %>%
  filter(anydate(time) >= as.Date("2015-06-01") & anydate(time) < as.Date("2015-08-01"))
x15.data <- cal.split(curve.lists$curve.list.x$x15.merge) %>%
  filter(anydate(time) >= as.Date("2015-08-01") & anydate(time) < as.Date("2015-10-01"))
f16.data <- cal.split(curve.lists$curve.list.f$f16.merge) %>%
  filter(anydate(time) >= as.Date("2015-10-01") & anydate(time) < as.Date("2015-12-01"))
h16.data <- cal.split(curve.lists$curve.list.h$h16.merge) %>%
  filter(anydate(time) >= as.Date("2015-12-01") & anydate(time) < as.Date("2016-02-01"))
cal15.16 <- rbind(k15.data, n15.data, u15.data, x15.data, f16.data, h16.data)

## contracts K16 - H17
k16.data <- cal.split(curve.lists$curve.list.k$k16.merge) %>%
  filter(anydate(time) >= as.Date("2016-02-01") & anydate(time) < as.Date("2016-04-01"))
n16.data <- cal.split(curve.lists$curve.list.n$n16.merge) %>%
  filter(anydate(time) >= as.Date("2016-04-01") & anydate(time) < as.Date("2016-06-01"))
u16.data <- cal.split(curve.lists$curve.list.u$u16.merge) %>%
  filter(anydate(time) >= as.Date("2016-06-01") & anydate(time) < as.Date("2016-08-01"))
x16.data <- cal.split(curve.lists$curve.list.x$x16.merge) %>%
  filter(anydate(time) >= as.Date("2016-08-01") & anydate(time) < as.Date("2016-10-01"))
f17.data <- cal.split(curve.lists$curve.list.f$f17.merge) %>% 
  filter(anydate(time) >= as.Date("2016-10-01") & anydate(time) < as.Date("2016-12-01"))
h17.data <- cal.split(curve.lists$curve.list.h$h17.merge) %>%
  filter(anydate(time) >= as.Date("2016-12-01") & anydate(time) < as.Date("2017-02-01"))
cal16.17 <- rbind(k16.data, n16.data, u16.data, x16.data, f17.data, h17.data)

## contracts K17 - H18
k17.data <- cal.split(curve.lists$curve.list.k$k17.merge) %>%
  filter(anydate(time) >= as.Date("2017-02-01") & anydate(time) < as.Date("2017-04-01"))
n17.data <- cal.split(curve.lists$curve.list.n$n17.merge) %>%
  filter(anydate(time) >= as.Date("2017-04-01") & anydate(time) < as.Date("2017-06-01"))
u17.data <- cal.split(curve.lists$curve.list.u$u17.merge) %>%
  filter(anydate(time) >= as.Date("2017-06-01") & anydate(time) < as.Date("2017-08-01"))
x17.data <- cal.split(curve.lists$curve.list.x$x17.merge) %>%
  filter(anydate(time) >= as.Date("2017-08-01") & anydate(time) < as.Date("2017-10-01"))
f18.data <- cal.split(curve.lists$curve.list.f$f18.merge) %>%
  filter(anydate(time) >= as.Date("2017-10-01") & anydate(time) < as.Date("2017-12-01"))
h18.data <- cal.split(curve.lists$curve.list.h$h18.merge) %>%
  filter(anydate(time) >= as.Date("2017-12-01") & anydate(time) < as.Date("2018-02-01"))
cal17.18 <- rbind(k17.data, n17.data, u17.data, x17.data, f18.data, h18.data)

## contracts K18 - H19
k18.data <- cal.split(curve.lists$curve.list.k$k18.merge) %>%
  filter(anydate(time) >= as.Date("2018-02-01") & anydate(time) < as.Date("2018-04-01"))
n18.data <- cal.split(curve.lists$curve.list.n$n18.merge) %>%
  filter(anydate(time) >= as.Date("2018-04-01") & anydate(time) < as.Date("2018-06-01"))
u18.data <- cal.split(curve.lists$curve.list.u$u18.merge) %>%
  filter(anydate(time) >= as.Date("2018-06-01") & anydate(time) < as.Date("2018-08-01"))
x18.data <- cal.split(curve.lists$curve.list.x$x18.merge) %>%
  filter(anydate(time) >= as.Date("2018-08-01") & anydate(time) < as.Date("2018-10-01"))
f19.data <- cal.split(curve.lists$curve.list.f$f19.merge) %>%
  filter(anydate(time) >= as.Date("2018-10-01") & anydate(time) < as.Date("2018-12-01"))
h19.data <- cal.split(curve.lists$curve.list.h$h19.merge) %>%
  filter(anydate(time) >= as.Date("2018-12-01") & anydate(time) < as.Date("2019-02-01"))
cal18.19 <- rbind(k18.data, n18.data, u18.data, x18.data, f19.data, h19.data)

## contracts K19 - H20
k19.data <- cal.split(curve.lists$curve.list.k$k19.merge) %>%
  filter(anydate(time) >= as.Date("2019-02-01") & anydate(time) < as.Date("2019-04-01"))
n19.data <- cal.split(curve.lists$curve.list.n$n19.merge) %>%
  filter(anydate(time) >= as.Date("2019-04-01") & anydate(time) < as.Date("2019-06-01"))
u19.data <- cal.split(curve.lists$curve.list.u$u19.merge) %>%
  filter(anydate(time) >= as.Date("2019-06-01") & anydate(time) < as.Date("2019-08-01"))
x19.data <- cal.split(curve.lists$curve.list.x$x19.merge) %>%
  filter(anydate(time) >= as.Date("2019-08-01") & anydate(time) < as.Date("2019-10-01"))
f20.data <- cal.split(curve.lists$curve.list.f$f20.merge) %>%
  filter(anydate(time) >= as.Date("2019-10-01") & anydate(time) < as.Date("2019-12-01"))
h20.data <- cal.split(curve.lists$curve.list.h$h20.merge) %>%
  filter(anydate(time) >= as.Date("2019-12-01") & anydate(time) < as.Date("2020-02-01"))
cal19.20 <- rbind(k19.data, n19.data, u19.data, x19.data, f20.data, h20.data)

## contracts K20- H21
k20.data <- cal.split(curve.lists$curve.list.k$k20.merge) %>%
  filter(anydate(time) >= as.Date("2020-02-01") & anydate(time) < as.Date("2020-04-01"))
n20.data <- cal.split(curve.lists$curve.list.n$n20.merge) %>%
  filter(anydate(time) >= as.Date("2020-04-01") & anydate(time) < as.Date("2020-06-01"))
u20.data <- cal.split(curve.lists$curve.list.u$u20.merge) %>%
  filter(anydate(time) >= as.Date("2020-06-01") & anydate(time) < as.Date("2020-08-01"))
x20.data <- cal.split(curve.lists$curve.list.x$x20.merge) %>%
  filter(anydate(time) >= as.Date("2020-08-01") & anydate(time) < as.Date("2020-10-01"))
f21.data <- cal.split(curve.lists$curve.list.f$f21.merge) %>%
  filter(anydate(time) >= as.Date("2020-10-01") & anydate(time) < as.Date("2020-12-01"))
h21.data <- cal.split(curve.lists$curve.list.h$h21.merge) %>%
  filter(anydate(time) >= as.Date("2020-12-01") & anydate(time) < as.Date("2021-02-01"))
cal20.21<- rbind(k20.data, n20.data, u20.data, x20.data, f21.data, h21.data)

## contracts K21- H22
k21.data <- cal.split(curve.lists$curve.list.k$k21.merge) %>%
  filter(anydate(time) >= as.Date("2021-02-01") & anydate(time) < as.Date("2021-04-01"))
n21.data <- cal.split(curve.lists$curve.list.n$n21.merge) %>%
  filter(anydate(time) >= as.Date("2021-04-01") & anydate(time) < as.Date("2021-06-01"))
u21.data <- cal.split(curve.lists$curve.list.u$u21.merge) %>%
  filter(anydate(time) >= as.Date("2021-06-01") & anydate(time) < as.Date("2021-08-01"))
x21.data <- cal.split(curve.lists$curve.list.x$x21.merge) %>%
  filter(anydate(time) >= as.Date("2021-08-01") & anydate(time) < as.Date("2021-10-01"))
f22.data <- cal.split(curve.lists$curve.list.f$f22.merge) %>%
  filter(anydate(time) >= as.Date("2021-10-01") & anydate(time) < as.Date("2021-12-01"))
h22.data <- cal.split(curve.lists$curve.list.h$h22.merge) %>%
  filter(anydate(time) >= as.Date("2021-12-01") & anydate(time) < as.Date("2022-02-01"))
cal21.22 <- rbind(k21.data, n21.data, u21.data, x21.data, f22.data, h22.data)

## contracts K22- H23
k22.data <- cal.split(curve.lists$curve.list.k$k22.merge) %>%
  filter(anydate(time) >= as.Date("2022-02-01") & anydate(time) < as.Date("2022-04-01"))
n22.data <- cal.split(curve.lists$curve.list.n$n22.merge) %>%
  filter(anydate(time) >= as.Date("2022-04-01") & anydate(time) < as.Date("2022-06-01"))
u22.data <- cal.split(curve.lists$curve.list.u$u22.merge) %>%
  filter(anydate(time) >= as.Date("2022-06-01") & anydate(time) < as.Date("2022-08-01"))
x22.data <- cal.split(curve.lists$curve.list.x$x22.merge) %>%
  filter(anydate(time) >= as.Date("2022-08-01") & anydate(time) < as.Date("2022-10-01"))
f23.data <- cal.split(curve.lists$curve.list.f$f23.merge) %>%
  filter(anydate(time) >= as.Date("2022-10-01") & anydate(time) < as.Date("2022-12-01"))
h23.data <- cal.split(curve.lists$curve.list.h$h23.merge) %>%
  filter(anydate(time) >= as.Date("2022-12-01") & anydate(time) < as.Date("2023-02-01"))
cal22.23 <- rbind(k22.data, n22.data, u22.data, x22.data, f23.data, h23.data)

## contracts K23 - H24 (note: back contracts here have minimal volume) 
k23.data <- cal.split(curve.lists$curve.list.k$k23.merge) %>%
  filter(anydate(time) >= as.Date("2023-02-01") & anydate(time) < as.Date("2023-04-01"))
n23.data <- cal.split(curve.lists$curve.list.n$n23.merge) %>%
  filter(anydate(time) >= as.Date("2023-04-01") & anydate(time) < as.Date("2023-06-01"))
u23.data <- cal.split(curve.lists$curve.list.u$u23.merge) %>%
  filter(anydate(time) >= as.Date("2023-06-01") & anydate(time) < as.Date("2023-08-01"))
x23.data <- cal.split(curve.lists$curve.list.x$x23.merge) %>%
  filter(anydate(time) >= as.Date("2023-08-01") & anydate(time) < as.Date("2023-10-01"))
f24.data <- cal.split(curve.lists$curve.list.f$f24.merge) %>%
  filter(anydate(time) >= as.Date("2023-10-01") & anydate(time) < as.Date("2023-12-01"))
h24.data <- cal.split(curve.lists$curve.list.h$h24.merge) %>%
  filter(anydate(time) >= as.Date("2023-12-01") & anydate(time) < as.Date("2024-02-01"))
cal23.24 <- rbind(k23.data, n23.data, u23.data, x23.data, f24.data, h24.data)


full.curve <- rbind(cal12.13, cal13.14, cal14.15, cal15.16, cal16.17, cal17.18,
                    cal18.19, cal19.20, cal20.21, cal21.22, cal22.23, cal23.24)
ts.plot(full.curve[,2:3], col = viridis(20)[c(5,15)], 
        main = "6-Month and 12-Month Soybean Short Calendar Spread", 
        xlab = "Time", ylab = "Price")
abline(h = 0, col = "red", lty = 2)
legend(2000,400, c("6MO", "12MO"), lty = c(1,1), col = viridis(20)[c(5,15)])
```

```{r, FORWARD CURVE BASIC ANALYSIS}
mean(sign(full.curve$six.mo) == sign(full.curve$year))
max(abs(full.curve$six.mo))
max(abs(full.curve$year))

mean(abs(full.curve$six.mo) > abs(full.curve$year))
mean(full.curve$year)
mean(full.curve$six.mo)
```

### PART 2: JOHANSEN TEST AND FULL COINTEGRATION  

```{r, PART 2 JOHANSEN TEST FULL DATASET}
## naive VAR fit for full dataset
full.crush.lag <- VARselect(crush.dat[,2:4], lag.max = 9, type = "none")
full.crush.lag$selection 

norm.crush.lag <- VARselect(crush.normalized[,2:4], lag.max = 9, type = "none")
norm.crush.lag$selection

## unit root checks in ZS, ZL, ZM series 
zs.unit.stat <- summary(ur.df(crush.dat$ZS, type = "drift", selectlags = "AIC"))
zl.unit.stat <- summary(ur.df(crush.dat$ZL, type = "drift", selectlags = "AIC"))
zm.unit.stat <- summary(ur.df(crush.dat$ZM, type = "drift", selectlags = "AIC"))
comp.stat <- zs.unit.stat@cval[3]
zs.unit.stat@teststat[1] < comp.stat
zl.unit.stat@teststat[1] < comp.stat
zm.unit.stat@teststat[1] < comp.stat

## verify ZS, ZL, ZM are I(1) 
zs.diff.stat <- summary(ur.df(diff(crush.dat$ZS), type = "drift", selectlags = "AIC"))
zl.diff.stat <- summary(ur.df(diff(crush.dat$ZL), type = "drift", selectlags = "AIC"))
zm.diff.stat <- summary(ur.df(diff(crush.dat$ZM), type = "drift", selectlags = "AIC"))
comp.stat.1 <- zs.diff.stat@cval[1]
zs.diff.stat@teststat[1] < comp.stat.1
zl.diff.stat@teststat[1] < comp.stat.1
zm.diff.stat@teststat[1] < comp.stat.1

## trace and eigenvalue statistics; both suggest rank 1 cointegration
full.eigenstat <- ca.jo(crush.dat[,2:4], type = "eigen", ecdet = "none", 
                        K = 5, spec = "transitory")
summary(full.eigenstat)
full.tracestat <- ca.jo(crush.dat[,2:4], type = "trace", ecdet = "none", 
                        K = 5, spec = "transitory")
summary(full.tracestat)

full.norm.eigenstat <- ca.jo(crush.normalized[,2:4], type = "eigen", ecdet = "none", 
                        K = 5, spec = "transitory")
summary(full.norm.eigenstat)

full.norm.tracestat <- ca.jo(crush.normalized[,2:4], type = "trace", ecdet = "none", 
                        K = 5, spec = "transitory")
summary(full.norm.tracestat)

## fitted as VECM
full.vecm <- VECM(crush.dat[,2:4], r = 1, lag = 4, include = "const", 
                  estim = "ML", LRinclude = "none")
rank.test(full.vecm)

full.vecm.norm <- VECM(crush.normalized[,2:4], r = 1, lag = 4, include = "const", 
                  estim = "ML", LRinclude = "none")
rank.test(full.vecm.norm)

summary(full.vecm.norm)
```

Maximum eigenvalue and trace statistics suggest cointegration rank 1. Note this result assumes cointegration remains constant over the entire timeframe considered. 

```{r, FULL TIMEFRAME JOHANSEN TEST RESULT ANALYSIS, fig.align="center", out.width="50%"}
## coefficient collection 
summary(full.vecm.norm)
full.beta <- coefB(full.vecm.norm)
full.alpha <- coefA(full.vecm.norm)
full.zt <- crush.normalized$ZS*full.beta[1] + crush.normalized$ZL*full.beta[2] +
  crush.normalized$ZM*full.beta[3]
ts.plot(cbind(full.zt, normalized.crush.value), 
        main = "Cointegration Residual and Board Crush", 
        xlab = "Time", ylab = "Value", 
        lty = c(1,2), col = rainbow(3)[c(1,3)])
legend("bottomright", legend = c("Cointegration Residual", "Board Crush"),
       col = rainbow(3)[c(1,3)], lty = 1:2, cex = 0.8, bg = "white")


ur.df(full.zt, type = "drift", selectlags = "AIC")
adf.test(full.zt)

mean(full.zt/normalized.crush.value)
mean((full.zt < normalized.crush.value))

mean(full.zt[2250:length(full.zt)]/normalized.crush.value[2250:length(full.zt)])
mean(full.zt[2250:length(full.zt)] < normalized.crush.value[2250:length(full.zt)])
```

```{r, RESULTING VECM DIAGNOSTICS}
## checks for residual normality and autocorrelation
var.formulation <- vec2var(full.norm.tracestat)
normality.test(var.formulation)
serial.test(var.formulation)
## model fails both tests; indicates nonnormal, autocorrelated residuals 
```

ADF test suggests stationarity in $z_t = \beta y_t$ process, but VECM parameters poorly estimated based on normality and autocorrelation tests. Problematic tests noted for future reference, but as main focus is estimating cointegration rank and relation rather than full VECM, ignored for now. 

```{r, PART 3 ROLLING WINDOW}
## construct 90 day intervals 
dt.split <- data.frame(as.Date(anydate(crush.dat$dt)))
colnames(dt.split) <- c("date")
dt.split <- dt.split %>% mutate(diff = as.numeric(date - lag(date)))
dt.split$diff[1] <- 0

dt.window <- dt.split %>% mutate(num.index = cumsum(diff))

## sliding window function 
window.min.max <- function(num.index, win.length, roll.length) {
  init.val <- (num.index - win.length) / roll.length
  window.hold <- floor(win.length / roll.length) - 1
  min.window <- floor(init.val) + 1
  max.window <- min.window + window.hold
  list(min.window, max.window)
}

## sliding window creation 
win.len.1 <- 120; win.len.2 <- 90; win.len.3 <- 60; win.len.4 <- 250
roll.len <- 5; n <- length(crush.dat[,1])

dt.window.1 <- dt.window %>%
  mutate(window.min = window.min.max(num.index, win.len.1, roll.len)[[1]], 
         window.max = window.min.max(num.index, win.len.1, roll.len)[[2]])
dt.window.2 <- dt.window %>%
  mutate(window.min = window.min.max(num.index, win.len.2, roll.len)[[1]], 
         window.max = window.min.max(num.index, win.len.2, roll.len)[[2]])
dt.window.3 <- dt.window %>%
  mutate(window.min = window.min.max(num.index, win.len.3, roll.len)[[1]], 
         window.max = window.min.max(num.index, win.len.3, roll.len)[[2]])
dt.window.4 <- dt.window %>%
  mutate(window.min = window.min.max(num.index, win.len.4, roll.len)[[1]], 
         window.max = window.min.max(num.index, win.len.4, roll.len)[[2]])

crush.window.1 <- crush.dat %>% 
  as.data.frame() %>%
  mutate(num.index = 0:(n-1)) %>% 
  mutate(window.min = window.min.max(num.index, win.len.1, roll.len)[[1]], 
         window.max = window.min.max(num.index, win.len.1, roll.len)[[2]])
 
crush.window.1.norm <- crush.normalized %>% 
  as.data.frame() %>%
  mutate(num.index = 0:(n-1)) %>% 
  mutate(window.min = window.min.max(num.index, win.len.1, roll.len)[[1]], 
         window.max = window.min.max(num.index, win.len.1, roll.len)[[2]])

crush.window.2 <- crush.dat %>% 
  as.data.frame() %>%
  mutate(num.index = 0:(n-1)) %>% 
  mutate(window.min = window.min.max(num.index, win.len.2, roll.len)[[1]], 
         window.max = window.min.max(num.index, win.len.2, roll.len)[[2]])

crush.window.2.norm <- crush.normalized %>% 
  as.data.frame() %>%
  mutate(num.index = 0:(n-1)) %>% 
  mutate(window.min = window.min.max(num.index, win.len.2, roll.len)[[1]], 
         window.max = window.min.max(num.index, win.len.2, roll.len)[[2]])

crush.window.3 <- crush.dat %>% 
  as.data.frame() %>%
  mutate(num.index = 0:(n-1)) %>% 
  mutate(window.min = window.min.max(num.index, win.len.3, roll.len)[[1]], 
         window.max = window.min.max(num.index, win.len.3, roll.len)[[2]])

crush.window.3.norm <- crush.normalized %>% 
  as.data.frame() %>%
  mutate(num.index = 0:(n-1)) %>% 
  mutate(window.min = window.min.max(num.index, win.len.3, roll.len)[[1]], 
         window.max = window.min.max(num.index, win.len.3, roll.len)[[2]])

crush.window.4.norm <- crush.normalized %>% 
  as.data.frame() %>%
  mutate(num.index = 0:(n-1)) %>% 
  mutate(window.min = window.min.max(num.index, win.len.4, roll.len)[[1]], 
         window.max = window.min.max(num.index, win.len.4, roll.len)[[2]])

crush.roll.window <- function(data) {
  max.window <- max(data$window.max)
  cr.vec <- rep(NA, max.window)
  
  for (i in 0:(max.window-5)) {
    temp.window <- data %>% filter(window.min <= i & window.max >= i)
    temp.vecm <- VECM(temp.window[,2:4], lag = 4, estim = "ML", include = "const")
    temp.ranktest <- rank.test(temp.vecm, type = "trace", cval = 0.1)
    coint.rank <- temp.ranktest$r
    cr.vec[i+1] <- coint.rank
  }
  cr.vec
}

## 120 day roll period  
roll.120day <- crush.roll.window(crush.window.1)
index.min <- seq(1, 2996, by = 5)
index.max.1 <- seq(121, 3116, by = 5)
cr.ind.1 <- cbind(na.omit(roll.120day), index.min, index.max.1)
data.frame(cr.ind.1)

## 90 day roll period 
roll.90day <- crush.roll.window(crush.window.2) 
index.max.2 <- seq(91, 3086, by = 5)
cr.ind.2 <- cbind(na.omit(roll.90day), index.min, index.max.2)
data.frame(cr.ind.2)

## 60 day roll period 
roll.60day <- crush.roll.window(crush.window.3) 
index.max.3 <- seq(61, 3056, by = 5)
cr.ind.3 <- cbind(na.omit(roll.60day), index.min, index.max.3)
data.frame(cr.ind.3)
```

```{r, PART 3 NORMALIZED ROLL WINDOWS}
## normalized 120 day roll
roll.120norm <- crush.roll.window(crush.window.1.norm)
cr.norm.1 <- cbind(na.omit(roll.120norm), index.min, index.max.1)
data.frame(cr.norm.1)

length((cr.norm.1 %>% data.frame %>% filter(V1 == 1))[,1])
cr.norm.1 %>% data.frame() %>% filter(V1 == 2)

## normalized 90 day roll 
roll.90norm <- crush.roll.window(crush.window.2.norm) 
cr.norm.2 <- cbind(na.omit(roll.90norm), index.min, index.max.2)
data.frame(cr.norm.2)

length((cr.norm.2 %>% data.frame %>% filter(V1 == 1))[,1])
cr.norm.2 %>% data.frame() %>% filter(V1 == 2)
## normalized 60 day roll 
roll.60norm <- crush.roll.window(crush.window.3.norm) 
cr.norm.3 <- cbind(na.omit(roll.60norm), index.min, index.max.3)
data.frame(cr.norm.3)

length((cr.norm.3 %>% data.frame %>% filter(V1 == 1))[,1])
cr.norm.3 %>% data.frame() %>% filter(V1 == 2)

## normalize 240 day roll 
roll.240norm <- crush.roll.window(crush.window.4.norm) 
cr.norm.4 <- cbind(na.omit(roll.240norm), index.min, index.max.3)
data.frame(cr.norm.4)
```

Difficult to identify meaningful cointegration from the raw rolling window -- see example 5 in synthetic data for rationale; some sort of dynamic windowing may be appropriate. 

```{r, PART 3 COINTEGRATION ANGLES}
## fixed cointegration rank 1 cointegration vector angle calculation 
angle <- function(v1, v2) {
  theta <- acos(sum(v1*v2) / (norm(v1, type = "2")*norm(v2, type = "2")))
  theta
}

## angle calculation holding cointegration rank static at 1 
roll.angle.1 <- function(data, c.rank = 1) {
  max.window <- max(data$window.max) 
  angle.vec <- rep(NA, max.window)
  
  init.dat <- data %>% filter(window.min <= 0 & window.max >= 0)
  init.vecm <- VECM(init.dat[,2:4], r = c.rank, lag = 4, estim = "ML", include = "const")
  prev.beta <- coefB(init.vecm)
  
  for (i in 1:(max.window-5)) {
    temp.dat <- data %>% filter(window.min <= i & window.max >= i)
    temp.vecm <- VECM(temp.dat[,2:4], r = c.rank, 
                          lag = 4, estim = "ML", include = "const")
    temp.beta <- coefB(temp.vecm)
    temp.angle <- angle(temp.beta, prev.beta)
    angle.vec[i] <- temp.angle
    prev.beta <- temp.beta
  }
  angle.vec 
}

## cointegration vector selection 
roll.coef.1 <- function(data, c.rank = 1) {
  max.window <- max(data$window.max) 
  coef.list <- list()
  
  for (i in 0:(max.window-5)) {
    temp.dat <- data %>% filter(window.min <= i & window.max >= i)
    temp.vecm <- VECM(temp.dat[,2:4], r = c.rank, 
                          lag = 4, estim = "ML", include = "const")
    temp.beta <- coefB(temp.vecm)
    coef.list[[length(coef.list)+1]] <- temp.beta
  }
  coef.list 
}

```

```{r, ANGLE PLOTS }
angle.120day <- roll.angle.1(crush.window.1)
angle.90day <- roll.angle.1(crush.window.2)
angle.60day <- roll.angle.1(crush.window.3)

angle.120norm <- roll.angle.1(crush.window.1.norm)
angle.90norm <- roll.angle.1(crush.window.2.norm)
angle.60norm <- roll.angle.1(crush.window.3.norm)
angle.240norm <- roll.angle.1(crush.window.4.norm)

par(mfrow=c(1,3))
ts.plot(na.omit(angle.120day), main = "Angle Between CI Basis: Rank 1, 120 Day Roll", 
        ylab = "Angle", xlab = "Window")
ts.plot(na.omit(angle.90day), main = "Angle Between CI Basis: Rank 1, 90 Day Roll", 
        ylab = "Angle", xlab = "Window")
ts.plot(na.omit(angle.60day), main = "Angle Between CI Basis: Rank 1, 60 Day Roll", 
        ylab = "Angle", xlab = "Window")

par(mfrow=c(1,3))
ts.plot(na.omit(angle.120norm), 
        main = "Rank 1, Normalized 120 Day Roll", 
        ylab = "Angle", xlab = "Window")
ts.plot(na.omit(angle.90norm), 
        main = "Rank 1, Normalized 90 Day Roll", 
        ylab = "Angle", xlab = "Window")
ts.plot(na.omit(angle.60norm), 
        main = "Rank 1, Normalized 60 Day Roll", 
        ylab = "Angle", xlab = "Window")
ts.plot(na.omit(angle.240norm), 
        main = "Rank 1, Normalized 240 Day Roll", 
        ylab = "Angle", xlab = "Window")
```

```{r, COINTEGRATION VECTOR SELECTION }
## cointegration vector selection (overlapping windows)
coef60 <- roll.coef.1(crush.window.3.norm)
coef90 <- roll.coef.1(crush.window.2.norm)
coef120 <- roll.coef.1(crush.window.1.norm)
coef240 <- roll.coef.1(crush.window.4.norm)


avg.shift <- lapply(coef90, FUN = function(x) {x / c(1,-0.9,-1.1) - c(1,1,1)})
med.shift.ZL <- median(sapply(coef90[1:510], function(x) x[2]))
med.shift.ZM <- median(sapply(coef90[1:510], function(x) x[3]))

avg.shift.240 <- lapply(coef240, FUN = function(x) {x / c(1,-0.9,-1.1) - c(1,1,1)})
med.shift.ZL.240 <- median(sapply(coef240[1:510], function(x) x[2]))
med.shift.ZM.240 <- median(sapply(coef240[1:510], function(x) x[3]))

avg.shift.120 <- lapply(coef120, FUN = function(x) {x / c(1,-0.9,-1.1) - c(1,1,1)})
med.shift.ZL.120 <- median(sapply(coef120[1:510], function(x) x[2]))
med.shift.ZM.120 <- median(sapply(coef120[1:510], function(x) x[3]))

avg.shift.60 <- lapply(coef60, FUN = function(x) {x / c(1,-0.9,-1.1) - c(1,1,1)})
med.shift.ZL.60 <- median(sapply(coef60[1:510], function(x) x[2]))
med.shift.ZM.60 <- median(sapply(coef60[1:510], function(x) x[3]))
```

Still difficult to parse -- no extreme regime separation as seen in synthetic data example 5. Subsequent testing done with data split according to stable regions identified by 90-day angles. 

```{r, ROLL ANGLE RANK 2}
## projection 
proj.min.2d <- function(v1, v2, w1, w2) {
  pairs <- list(cbind(v1,w1), cbind(v1,w2), cbind(v2,w1), cbind(v2,w2))
  curr.min <- 1e6
  pair.min <- NA
  for (pair in pairs) {
    temp.len <- sum(pair[,1]*pair[,2]) / norm(pair[,2], type = "2")
    if (temp.len < curr.min) {
      pair.min <- pair
    }
  }
  pair.min 
}

## rank 2 angle calculation
roll.angle.2 <- function(data, c.rank = 2) {
  max.window <- max(data$window.max) 
  angle.vec <- rep(NA, max.window)
  
  init.dat <- data %>% filter(window.min <= 0 & window.max >= 0)
  init.vecm <- VECM(init.dat[,2:4], r = c.rank, lag = 4, estim = "ML", include = "const")
  prev.beta <- coefB(init.vecm)
  
  for (i in 1:(max.window-2)) {
    temp.dat <- data %>% filter(window.min <= i & window.max >= i)
    temp.vecm <- VECM(temp.dat[,2:4], r = c.rank, 
                          lag = 1, estim = "ML", include = "const")
    temp.beta <- coefB(temp.vecm)
    proj.pair <- proj.min.2d(temp.beta[,1], temp.beta[,2], 
                             prev.beta[,1], prev.beta[,2])
    temp.angle <- angle(proj.pair[,1], proj.pair[,2])
    angle.vec[i] <- temp.angle
    prev.beta <- temp.beta
  }
  angle.vec 
}

angle2.120norm <- roll.angle.2(crush.window.1.norm)
angle2.90norm <- roll.angle.2(crush.window.2.norm)
angle2.60norm <- roll.angle.2(crush.window.3.norm)

par(mfrow=c(1,3))
ts.plot(na.omit(angle2.120norm), 
        main = "Rank 2, Normalized 120 Day Roll", 
        ylab = "Angle", xlab = "Window")
ts.plot(na.omit(angle2.90norm), 
        main = "Rank 2, Normalized 90 Day Roll", 
        ylab = "Angle", xlab = "Window")
ts.plot(na.omit(angle2.60norm), 
        main = "Rank 2, Normalized 60 Day Roll", 
        ylab = "Angle", xlab = "Window")
```

```{r, STABLE WINDOW PERIODS}
## 120 day stable period selections and tests 
angle.breaks.temp.1 <- data.frame(cbind(na.omit(angle.120day), 1:599))
angle.breaks.1 <- angle.breaks.temp.1 %>% filter(X1 > 0.5) %>% dplyr::select(X2)

fixed.breakpoint.roll <- function(window.data, breakpoints) {
  rank.vec <- rep(NA, length(breakpoints))
  start.break <- 0
  
  for(i in 1:length(breakpoints[,1])) {
    end.break <- breakpoints[,1][i]
    temp.dat <- window.data %>% filter(window.min <= start.break & window.min <= end.break)
    temp.vecm <- VECM(temp.dat[,2:4], lag = 4, include = "const", estim = "ML")
    r <- rank.test(temp.vecm, cval = 0.10)$r
    start.break <- end.break
    rank.vec[i] <- r
  }
  rank.vec
}
cr.measure.1 <- fixed.breakpoint.roll(crush.window.1, angle.breaks.1)
cr.measure.1

## 90 day stable period selections and tests 
angle.breaks.temp.2 <- data.frame(cbind(na.omit(angle.90day), 1:599))
angle.breaks.2 <- angle.breaks.temp.2 %>% filter(X1 > 0.5) %>% dplyr::select(X2)

cr.measure.2 <- fixed.breakpoint.roll(crush.window.2, angle.breaks.2)
cr.measure.2

## 60 day stable period selections and tests
angle.breaks.temp.3 <- data.frame(cbind(na.omit(angle.60day), 1:599))
angle.breaks.3 <- angle.breaks.temp.3 %>% filter(X1 > 0.5) %>% dplyr::select(X2)

cr.measure.3 <- fixed.breakpoint.roll(crush.window.3, angle.breaks.3)
cr.measure.3
```

```{r}
## normalized 120 day stable period rank test
angle.norm.temp.1 <- data.frame(cbind(na.omit(angle.120norm), 1:599))
angle.norm.1 <- angle.norm.temp.1 %>% filter(X1 > 1.5) %>% dplyr::select(X2)

cr.norm.1 <- fixed.breakpoint.roll(crush.window.1.norm, angle.norm.1)
cr.norm.1

## normalized 90 day stable period rank tests
angle.norm.temp.2 <- data.frame(cbind(na.omit(angle.90norm), 1:599))
angle.norm.2 <- angle.norm.temp.2 %>% filter(X1 > 1.5) %>% dplyr::select(X2)

cr.norm.2 <- fixed.breakpoint.roll(crush.window.2.norm, angle.norm.2)
cr.norm.2

## 240 day stable period selections and tests 
angle.norm.temp.4 <- data.frame(cbind(na.omit(angle.240norm), 1:599))
angle.norm.4 <- angle.breaks.temp.4 %>% filter(X1 > 1.5) %>% dplyr::select(X2)

cr.norm.4 <- fixed.breakpoint.roll(crush.window.4.norm, angle.norm.4)
cr.norm.4
```

```{r, PART 4 WINDOW IDENTIFICATION}
## identify regime shifts in future curve
full.curve.sgn <- full.curve %>%
  mutate(six.sgn = sign(six.mo), year.sgn = sign(year), 
         six.shift = lag(six.sgn), year.shift = lag(year.sgn))

regime.shift.1 <- full.curve.sgn %>% 
  filter(six.sgn != six.shift | is.na(six.shift)) %>%
  dplyr::select(time, six.mo, six.sgn, six.shift)
colnames(regime.shift.1) <- c("dt", "six.mo", "six.sgn", "six.shift")

regime.shift.2 <- full.curve.sgn %>% 
  filter(year.sgn != year.shift | is.na(year.shift)) %>%
  dplyr::select(time, year, year.sgn, year.shift)
colnames(regime.shift.2) <- c("dt", "year", "year.sgn", "year.shift")

## isolate breakpoints of interest 
crush.window.six <- left_join(crush.normalized, regime.shift.1, by = "dt")
crush.window.year <- left_join(crush.normalized, regime.shift.2, by = "dt")

crush.breaks.six <- drop_na(crush.window.six)$dt
crush.breaks.year <- drop_na(crush.window.year)$dt

break.indices.six <- match(crush.breaks.six, crush.window.six$dt)
six.past <- break.indices.six - lag(break.indices.six)
six.lead.lag <- data.frame(cbind(break.indices.six, six.past))
break.six <- six.lead.lag %>%
  mutate(iso = ifelse((six.past > 240), 1, 
                      ifelse((six.past > 120), 2, 0))) %>%
  dplyr::select(break.indices.six, iso)

break.indices.year <- match(crush.breaks.year, crush.window.year$dt)
year.past <- break.indices.year - lag(break.indices.year)
year.lead.lag <- data.frame(cbind(break.indices.year, year.past))
break.year <- year.lead.lag %>%
  mutate(iso = ifelse((year.past > 240), 1, 
                      ifelse((year.past > 120), 2, 0))) %>%
  dplyr::select(break.indices.year, iso)

data.frame(break.six); data.frame(break.year)
```

```{r, PART 4 REGIME-DEPENDENT COINTEGRATION BREAKS}
## windowed cointegration rank check
coint.fixed.window <- function(data, break.vec, c.rank = 1){
  win.start <- data$dt[1]
  cr.vec <- rep(NA, length(break.vec)); counter <- 1
  
  while(counter < length(break.vec)) {
    win.end <- break.vec[counter+1]
    temp.dat <- data %>% filter(dt >= win.start & dt <= win.end)
    
    # extend window to capture sufficient data
    if(length(temp.dat[,1]) < 30) {
      counter <- counter + 1
      next 
    } 
    else {
      temp.vecm <- VECM(temp.dat[,2:4], r = c.rank, 
                        lag = 4, estim = "ML", include = "const")
      temp.rank <- rank.test(temp.vecm)$r
      cr.vec[counter] <- temp.rank
      win.start <- win.end 
    }
    counter <- counter + 1
  }
  cr.vec
}

cr.six.regimes <- cbind(coint.fixed.window(crush.normalized, crush.breaks.six),
                        crush.breaks.six)
cr.year.regimes <- cbind(coint.fixed.window(crush.normalized, crush.breaks.year),
                         crush.breaks.year)

cr.six.comp <- data.frame(na.omit(cr.six.regimes))
cr.year.comp <- data.frame(na.omit(cr.year.regimes))
```

```{r, PART 4 VERIFYING INTERVALS}
cr.six.comp  # cointegration between regime shifts (6 month)
cr.year.comp  # cointegration between regime shifts (12 month)
```

```{r}
temp <- filter.dates(crush.normalized, start = 1598400000)
summary(ca.jo(temp[,2:4], type = "trace", ecdet = "none", K = 4, spec = "transitory"))
```

23 distinct cointegration (or lack thereof) regions identified based on six-month spread; 18 identified based on yearlong spread. 

```{r, PART 4 COMPACT REGIME DEPENDENT INTERVALS}
filter.dates <- function(dat, start=-1e10, end=1e10) {
  new.dat <- dat %>% filter(dt > start & dt <= end)
  new.dat
}

roll.coef.1 <- function(data, c.rank = 1) {
  max.window <- max(data$window.max) 
  coef.list <- list()
  
  for (i in 0:(max.window-5)) {
    temp.dat <- data %>% filter(window.min <= i & window.max >= i)
    temp.vecm <- VECM(temp.dat[,2:4], r = c.rank, 
                          lag = 4, estim = "ML", include = "const")
    temp.beta <- coefB(temp.vecm)
    coef.list[[length(coef.list)+1]] <- temp.beta
  }
  coef.list 
}

## strongest rank 1 cointegration when both spreads approx flat?
filter.roll.1 <- function(data, filter.vec, c.rank=1) {
  coef.list <- list()
  
  init.dat <- filter.dates(data, end = filter.vec[1])
  init.vecm <- VECM(init.dat[,2:4], r = c.rank, 
                    lag = 4, estim = "ML", include = "const")
  init.beta <- coefB(init.vecm)
  coef.list[[1]] <- init.beta
  
  for(i in 1:(length(filter.vec)-1)){
    temp.dat <- filter.dates(data, filter.vec[i], filter.vec[i+1])
    temp.vecm <- VECM(temp.dat[,2:4], r = c.rank, 
                          lag = 4, estim = "ML", include = "const")
    temp.beta <- coefB(temp.vecm)
    coef.list[[length(coef.list)+1]] <- temp.beta
  }
  
  coef.list
}

regime.coint.1 <- filter.roll.1(crush.normalized, cr.six.comp[,2][2:19])
med.ZLreg <- median(sapply(regime.coint.1, function(x) x[2]))
med.ZMreg <- median(sapply(regime.coint.1, function(x) x[3]))
```

```{r, PART 5 INFORMED REGIME WINDOWS}
## repeating process above with specified isolated and semi-isolated breakpoints
iso.six <- (break.six %>% filter(iso == 1))$break.indices.six
semi.iso.six <- (break.six %>% filter(iso > 0))$break.indices.six

iso.year <- (break.year %>% filter(iso == 1))$break.indices.year
semi.iso.year <- (break.year %>% filter(iso > 0))$break.indices.year

iso.rank <- function(data, break.indices) {
  start.window <- 1
  cr.vec <- rep(NA, length(break.indices) + 1)
  for(i in 1:length(break.indices)) {
    end.window <- break.indices[i]
    temp.dat <- data[start.window:end.window, 2:4]
    temp.vecm <- VECM(temp.dat, lag = 4, r = 1, include = "const", estim = "ML")
    temp.rank <- rank.test(temp.vecm, cval = 0.1)$r
    cr.vec[i] <- temp.rank 
    start.window <- end.window
  }
  
  last.dat <- data[start.window:length(data[,1]), 2:4]
  last.vecm <- VECM(last.dat, lag = 4, r = 1, include = "const", estim = "ML")
  last.rank <- rank.test(last.vecm, cval = 0.1)$r
  cr.vec[length(break.indices)+1] <- last.rank
  cr.vec
}

iso.rank1 <- function(data, break.indices) {
  start.window <- 1
  coef.list <- list()
  for(i in 1:length(break.indices)) {
    end.window <- break.indices[i]
    temp.dat <- data[start.window:end.window, 2:4]
    temp.vecm <- VECM(temp.dat, r = 1, lag = 4, include = "const", estim = "ML")
    temp.coef <- coefB(temp.vecm)
    coef.list[[i]] <- temp.coef 
    start.window <- end.window
  }
  
  last.dat <- data[start.window:length(data[,1]), 2:4]
  last.vecm <- VECM(last.dat, r = 1, lag = 4, include = "const", estim = "ML")
  last.coef <- coefB(last.vecm)
  coef.list[[length(coef.list)+1]] <- last.coef
  coef.list
}

six.shift <- iso.rank(crush.normalized, semi.iso.six)
year.shift <- iso.rank(crush.normalized, semi.iso.year)

six.coef <- iso.rank1(crush.normalized, semi.iso.six)
med.ZL6 <- mean(sapply(six.coef, function(x) x[2]))
med.ZM6 <- mean(sapply(six.coef, function(x) x[3]))

```

